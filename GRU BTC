import pandas as pd
import numpy as np
import ccxt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from scikeras.wrappers import KerasRegressor
from sklearn.model_selection import GridSearchCV
import ta
import seaborn as sns
import matplotlib.pyplot as plt


# Define the neural network model architecture
def create_model(optimizer='adam'):
    model = Sequential()
    model.add(GRU(units=200, dropout=0, input_shape=(x_train.shape[1], x_train.shape[2]), activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer=optimizer, loss='mean_squared_error')
    return model


# Initialize the Binance client
binance = ccxt.binance()

## MY CHANGES TO THE FETCHING FUNCTION:
def fetch_open_interest_hist(symbol, period="1d", limit=30, startTime=None, endTime=None):
    # Construct the URL
    url = 'futures/data/openInterestHist'
    params = {
        'symbol': symbol,
        'period': period,
        'limit': limit,
        'startTime': startTime,
        'endTime': endTime
    }

    # Filter out None values from the params
    params = {k: v for k, v in params.items() if v is not None}


    # Fetch the data
    #response = binance.request(url, method='GET', params=params)
    response = requests.get(f'https://www.binance.com/futures/data/openInterestHist?symbol={symbol}&period={period}&limit={limit}')
    print(response.data)
    return pd.DataFrame(response)

    print(df)




# Function to fetch top trader long/short ratio (Accounts)
def fetch_top_long_short_account_ratio(symbol, period='1d', limit=30, startTime=None, endTime=None):
    # Construct the URL
    url = '/futures/data/topLongShortAccountRatio'
    params = {
        'symbol': symbol,
        'period': period,
        'limit': limit,
        'startTime': startTime,
        'endTime': endTime
    }

    # Filter out None values from the params
    params = {k: v for k, v in params.items() if v is not None}

    # Fetch the data
    response = binance.request(url, method='GET', params=params)

    return pd.DataFrame(response)

# Function to fetch top trader long/short ratio (Positions)
def fetch_top_long_short_position_ratio(symbol, period='1d', limit=30, startTime=None, endTime=None):
    # Construct the URL
    url = '/futures/data/topLongShortPositionRatio'
    params = {
        'symbol': symbol,
        'period': period,
        'limit': limit,
        'startTime': startTime,
        'endTime': endTime
    }

    # Filter out None values from the params
    params = {k: v for k, v in params.items() if v is not None}

    # Fetch the data
    response = binance.request(url, method='GET', params=params)

    return pd.DataFrame(response)

# Function to fetch long/short ratio
def fetch_global_long_short_account_ratio(symbol, period='1d', limit=30, startTime=None, endTime=None):
    # Construct the URL
    url = '/futures/data/globalLongShortAccountRatio'
    params = {
        'symbol': symbol,
        'period': period,
        'limit': limit,
        'startTime': startTime,
        'endTime': endTime
    }

    # Filter out None values from the params
    params = {k: v for k, v in params.items() if v is not None}

    # Fetch the data
    response = binance.request(url, method='GET', params=params)

    return pd.DataFrame(response)

# Function to fetch taker buy/sell volume
def fetch_taker_long_short_ratio(symbol, period='1d', limit=30, startTime=None, endTime=None):

    # Construct the URL
    url = '/futures/data/takerlongshortRatio'
    params = {
        'symbol': symbol,
        'period': period,
        'limit': limit,
        'startTime': startTime,
        'endTime': endTime
    }

    # Filter out None values from the params
    params = {k: v for k, v in params.items() if v is not None}

    # Fetch the data
    response = binance.request(url, method='GET', params=params)

    # Convert the response into a pandas DataFrame
    df = pd.DataFrame(response)
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')

    return df

# Function to fetch premium index kline data and convert to DataFrame
def fetch_premium_ohlcv(symbol, interval='1d', startTime=None, endTime=None, limit=1500):
    endpoint = '/fapi/v1/premiumIndexKlines'
    url = binance.urls['api']['fapiPublic'] + '/premiumIndexKlines'
    params = {
        'symbol': symbol,
        'interval': interval,
        'startTime': startTime,
        'endTime': endTime,
        'limit': limit
    }

    # Convert params to query string and append to the URL
    url += '?' + '&'.join([f"{k}={v}" for k, v in params.items() if v is not None])
    response = binance.fetch(url, method='GET')
    df = pd.DataFrame(response, columns=['open_time', 'open', 'high', 'low', 'close', 'ignore1', 'open_time_close', 'ignore2', 'ignore3', 'ignore4', 'ignore5', 'ignore6'])
    df['open_time'] = df['open_time'].astype(np.int64)
    df['date'] = pd.to_datetime(df['open_time'], unit='ms')
    df = df[['date', 'open', 'high', 'low', 'close']]

    df.fillna(method='bfill', inplace=True)

    return df


# Function to fetch candlestick OHLCV kline data and convert to DataFrame
def fetch_ohlcv(symbol, interval='1d', startTime=None, endTime=None, limit=1500):
    response = binance.fetch_ohlcv(symbol, interval, since=startTime, limit=limit)
    df = pd.DataFrame(response, columns=['open_time', 'open', 'high', 'low', 'close', 'volume'])
    df['open_time'] = df['open_time'].astype(np.int64)
    df['date'] = pd.to_datetime(df['open_time'], unit='ms')
    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]
    df.fillna(method='ffill', inplace=True)
    return df

# Fetch the new datasets

df_kline = fetch_ohlcv('BTCUSDT')
df_premium = fetch_premium_ohlcv('BTCUSDT')

df_open_interest_hist = fetch_open_interest_hist('BTCUSDT')
df_open_interest_hist['timestamp'] = pd.to_datetime(df_open_interest_hist['timestamp'], unit='ms')

df_top_long_short_account = fetch_top_long_short_account_ratio('BTCUSDT')
df_top_long_short_account['timestamp'] = pd.to_datetime(df_top_long_short_account['timestamp'], unit='ms')

df_top_long_short_position = fetch_top_long_short_position_ratio('BTCUSDT')
df_top_long_short_position['timestamp'] = pd.to_datetime(df_top_long_short_position['timestamp'], unit='ms')

df_global_long_short = fetch_global_long_short_account_ratio('BTCUSDT')
df_global_long_short['timestamp'] = pd.to_datetime(df_global_long_short['timestamp'], unit='ms')

df_taker_long_short = fetch_taker_long_short_ratio('BTCUSDT')
df_taker_long_short['timestamp'] = pd.to_datetime(df_taker_long_short['timestamp'], unit='ms')

# Make sure the data is consistent in terms of timestamps
df_kline.set_index('date', inplace=True)
df_premium.set_index('date', inplace=True)

# Ensure they are aligned on the date index
df = pd.merge(df_kline, df_premium, left_index=True, right_index=True, how='outer', suffixes=('', '_premium'))

# Filter based on minimum date
min_start_date = max(df_kline['date'].min(), df_premium['date'].min())
df_kline = df_kline[df_kline['date'] >= min_start_date]
df_premium = df_premium[df_premium['date'] >= min_start_date]

# Merge the new datasets with the main dataframe
df = pd.merge(df, df_open_interest_hist, left_on='date', right_on='timestamp', how='left', suffixes=('', '_oih'))
df = pd.merge(df, df_top_long_short_account, left_on='date', right_on='timestamp', how='left', suffixes=('', '_tlsa'))
df = pd.merge(df, df_top_long_short_position, left_on='date', right_on='timestamp', how='left', suffixes=('', '_tlsp'))
df = pd.merge(df, df_global_long_short, left_on='date', right_on='timestamp', how='left', suffixes=('', '_gls'))
df = pd.merge(df, df_taker_long_short, left_on='date', right_on='timestamp', how='left', suffixes=('', '_tls'))

print(df.head(50))

# Technical indicators
df['RSI'] = ta.momentum.rsi(df['close'], fillna=True)
df['Bollinger_Band'] = ta.volatility.bollinger_hband(df["close"], fillna=True)
df['Standard_Deviation'] = df['close'].rolling(window=14).std()
df['Skewness'] = df['close'].rolling(window=14).apply(lambda x: x.skew(), raw=False)
df['Kurtosis'] = df['close'].rolling(window=14).apply(lambda x: x.kurtosis(), raw=False)
df['Z-Score'] = (df['close'] - df['close'].rolling(window=14).mean()) / df['Standard_Deviation']

df.fillna(method='bfill', inplace=True)

print(df)

# Use ALL the data
data = df.copy()

# Define the desired features for training
features = ['close', 'volume', 'RSI', 'Bollinger_Band', 'Standard_Deviation', 'Skewness', 'Kurtosis', 'Z-Score', 'open', 'high', 'low', 'sumOpenInterest', 'sumOpenInterestValue',
                 'longShortRatio_x', 'longAccount_x', 'shortAccount_x',
                 'longShortRatio_y', 'longAccount_y', 'shortAccount_y',
                 'buySellRatio', 'buyVol', 'sellVol']

# Use only training data for scaling
train_size = int(0.8 * len(df))
train_data = df.iloc[:train_size]

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data_train = scaler.fit_transform(train_data[features].values)
scaled_data = scaler.transform(df[features].values)

close_scaler = MinMaxScaler(feature_range=(0, 1))
scaled_close_train = close_scaler.fit_transform(train_data['close'].values.reshape(-1, 1))
scaled_close = close_scaler.transform(df['close'].values.reshape(-1, 1))

# Create a data structure with 128 timestamps and 1 output
x_train, y_train = [], []
for i in range(120, len(scaled_data)):
    x_train.append(scaled_data[i - 120:i])
    y_train.append(scaled_close[i, 0])

x_train, y_train = np.array(x_train), np.array(y_train)

# Predicting ~1 month into the future + the last actual day for continuity
n_future = 30
forecast_period_dates = pd.date_range(data['date'].iloc[-1], periods=n_future + 2, freq='1d')[1:]

model = create_model()
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model.fit(x_train, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

x_pred = [scaled_data[-120:]]  # Most recent data for the prediction

for _ in range(n_future):
    pred = model.predict(np.array([x_pred[-1]]))
    new_step = x_pred[-1][1:]
    new_step_values = new_step[-1].copy()
    new_step_values[0] = pred[0]
    new_step = np.append(new_step, new_step_values.reshape(1, -1), axis=0)
    x_pred.append(new_step)

forecast = model.predict(np.array(x_pred))
forecast_copies = np.repeat(forecast, len(features), axis=-1)
y_pred_future = close_scaler.inverse_transform(forecast_copies.reshape(-1, 1)).flatten()

# Appending the last real price to the start of our forecast
last_real_price = df['close'].iloc[-1]
y_pred_future = np.insert(y_pred_future, 0, last_real_price)

# Convert timestamp to date
forecast_dates = pd.to_datetime(forecast_period_dates)

# Predict October 31, 2023
x_pred_oct_31 = np.array([scaled_data[-120:]])
forecast_oct_31 = model.predict(x_pred_oct_31)
y_pred_oct_31 = close_scaler.inverse_transform(forecast_oct_31).flatten()[0]

# Print the predicted value for October 31, 2023
print("Predicted Bitcoin price for October 31, 2023: $", y_pred_oct_31)

# Adding the prediction for October 31 to the end of our forecasted values
y_pred_future = np.append(y_pred_future, y_pred_oct_31)

# Extend forecast dates to include October 31
forecast_period_dates = forecast_period_dates.append(pd.DatetimeIndex([pd.Timestamp('2023-10-31')]))

df_forecast = pd.DataFrame({'date': forecast_period_dates, 'close': y_pred_future})

# Plotting
plt.figure(figsize=(12, 6))
sns.lineplot(x='date', y='close', data=df)
sns.lineplot(x='date', y='close', data=df_forecast)
plt.scatter(pd.Timestamp('2023-10-31'), y_pred_oct_31, color='red', marker='o', label='Predicted for Oct 31, 2023')
plt.title('Bitcoin Price Prediction')
plt.xlabel('date')
plt.ylabel('price')
plt.legend(['Actual', 'Forecast', 'Predicted for Oct 31, 2023'])
plt.show()







